{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB1RDFMseYaC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHy74O02eLUo",
        "outputId": "00681bd8-4fdf-41f2-9396-9c778b56ab95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m604.2/611.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.activations import gelu\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBgZ4goDebl8"
      },
      "outputs": [],
      "source": [
        " class MultiHeadedAttention(tensorflow.keras.Model):\n",
        "    def __init__(self, dimension: int, heads: int = 8):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dimension = dimension\n",
        "        assert dimension // heads\n",
        "        self.depth = dimension // heads\n",
        "        self.wq = tensorflow.keras.layers.Dense(dimension)\n",
        "        self.wk = tensorflow.keras.layers.Dense(dimension)\n",
        "        self.wv = tensorflow.keras.layers.Dense(dimension)\n",
        "        self.dense = tensorflow.keras.layers.Dense(dimension)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        batch_size = tensorflow.shape(inputs)[0]\n",
        "        q: tensorflow.Tensor = self.wq(inputs)\n",
        "        k: tensorflow.Tensor = self.wk(inputs)\n",
        "        v: tensorflow.Tensor = self.wv(inputs)\n",
        "\n",
        "        def split_heads(x, batch_size):\n",
        "            x = tensorflow.reshape(x, (batch_size, -1, self.heads, self.depth))\n",
        "            return tensorflow.transpose(x, perm=[0,2,1,3])\n",
        "\n",
        "        q = split_heads(q, batch_size)\n",
        "        k = split_heads(k, batch_size)\n",
        "        v = split_heads(v, batch_size)\n",
        "\n",
        "        def scaled_dot_product_attention(q,k,v):\n",
        "            matmul_qk = tensorflow.matmul(q, k, transpose_b = True)\n",
        "            dk = tensorflow.cast(tensorflow.shape(k)[-1], tensorflow.float32)\n",
        "            scaled_attention_logits = matmul_qk / tensorflow.math.sqrt(dk)\n",
        "\n",
        "            softmax = tensorflow.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "            scaled_dot_product_attention_output = tensorflow.matmul(softmax, v)\n",
        "            return scaled_dot_product_attention_output, softmax\n",
        "\n",
        "        attention_weights, softmax = scaled_dot_product_attention(q, k, v)\n",
        "        scaled_attention = tensorflow.transpose(attention_weights, perm=[0,2,1,3])\n",
        "        concat_attention = tensorflow.reshape(scaled_attention, (batch_size, -1, self.dimension))\n",
        "        output = self.dense(concat_attention)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSMaJpvNedQA"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(tensorflow.keras.Model):\n",
        "    def __init__(self, residual_function):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.residual_function = residual_function\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.residual_function(inputs) + inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ovbWk8Aeen7"
      },
      "outputs": [],
      "source": [
        "class NormalizationBlock(tensorflow.keras.Model):\n",
        "    def __init__(self, norm_function, epsilon=1e-5):\n",
        "        super(NormalizationBlock, self).__init__()\n",
        "        self.norm_function = norm_function\n",
        "        self.normalize = tensorflow.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.norm_function(self.normalize(inputs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krRGnE4Aejni"
      },
      "outputs": [],
      "source": [
        "class MLPBlock(tensorflow.keras.Model):\n",
        "    def __init__(self, output_dimension, hidden_dimension):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.output_dimension = tensorflow.keras.layers.Dense(output_dimension)\n",
        "        self.hidden_dimension = tensorflow.keras.layers.Dense(hidden_dimension)\n",
        "        self.dropout1 = tensorflow.keras.layers.Dropout(0.1)\n",
        "        self.dropout2 = tensorflow.keras.layers.Dropout(0.1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        x = self.hidden_dimension(inputs)\n",
        "        x = gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.output_dimension(x)\n",
        "        x = gelu(x)\n",
        "        output = self.dropout2(x)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BwSKiW3elg_"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(tensorflow.keras.layers.Layer):\n",
        "    def __init__(self, dimension, depth, heads, mlp_dimension):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        layers_ = []\n",
        "        layers_.append(tensorflow.keras.Input(shape=((CFG.obj_image_size//CFG.patch_size)*(CFG.obj_image_size//CFG.patch_size)+1,dimension)))\n",
        "        for i in range(depth):\n",
        "            layers_.append(NormalizationBlock(ResidualBlock(MultiHeadedAttention(dimension, heads))))\n",
        "            layers_.append(NormalizationBlock(ResidualBlock(MLPBlock(dimension, mlp_dimension))))\n",
        "\n",
        "        self.layers_ = tensorflow.keras.Sequential(layers_)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layers_(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwyWjWq-empT"
      },
      "outputs": [],
      "source": [
        "class ImageTransformer(tensorflow.keras.Model):\n",
        "    def __init__(\n",
        "            self, image_size, patch_size, n_classes, batch_size,\n",
        "            dimension, depth, heads, mlp_dimension, channels=3):\n",
        "        super(ImageTransformer, self).__init__()\n",
        "        assert image_size % patch_size == 0, 'invalid patch size for image size'\n",
        "\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "        self.dimension = dimension\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.positional_embedding = self.add_weight(\n",
        "            \"position_embeddings\", shape=[num_patches + 1, dimension],\n",
        "            initializer=tensorflow.keras.initializers.RandomNormal(), dtype=tensorflow.float32\n",
        "        )\n",
        "        self.classification_token = self.add_weight(\n",
        "            \"classification_token\", shape=[1, 1, dimension],\n",
        "            initializer=tensorflow.keras.initializers.RandomNormal(), dtype=tensorflow.float32\n",
        "        )\n",
        "        self.heads = heads\n",
        "        self.depth = depth\n",
        "        self.mlp_dimension = dimension\n",
        "        self.n_classes = n_classes\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.patch_projection = tensorflow.keras.layers.Dense(dimension)\n",
        "        self.normalization2 = tensorflow.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.MLP = MLPBlock(self.dimension, self.mlp_dimension)\n",
        "        self.output_classes = tensorflow.keras.layers.Dense(self.n_classes)\n",
        "        self.transformer = TransformerEncoder(self.dimension, self.depth, self.heads, self.mlp_dimension)\n",
        "        self.dropout1 = tensorflow.keras.layers.Dropout(0.5)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        batch_size = tensorflow.shape(inputs)[0]\n",
        "\n",
        "        ###############################################\n",
        "        ############ 가장 중요한 부분 ##################\n",
        "        ###############################################\n",
        "\n",
        "        # 이미지를 patch_size로 조각낸다.\n",
        "        patches = tensorflow.image.extract_patches(\n",
        "            images = inputs,\n",
        "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
        "            strides = [1, self.patch_size, self.patch_size, 1],\n",
        "            rates = [1,1,1,1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tensorflow.reshape(patches, [batch_size, patches.shape[1]*patches.shape[2], patch_dims])\n",
        "        x = self.patch_projection(patches)\n",
        "\n",
        "        cls_pos = tensorflow.broadcast_to(\n",
        "            self.classification_token, [batch_size, 1, self.dimension]\n",
        "        )\n",
        "        x = tensorflow.concat([cls_pos, x], axis=1)\n",
        "        x = x + self.positional_embedding\n",
        "        x = self.transformer(x)\n",
        "        x = self.normalization2(x)\n",
        "        x = x[:,0,:]\n",
        "        x_keep = tensorflow.identity(x)\n",
        "        x = self.dropout1(x)\n",
        "        output = self.output_classes(x)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL3hE95Venka",
        "outputId": "cb277f32-36f9-45fb-c5ea-f20a0c4f92f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "# CIFAR10 데이터 다운로드\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images = train_images / 255.\n",
        "test_images = test_images / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulZ7ekpQeqI0"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    num_classes = 10\n",
        "    input_shape = (32, 32, 3)\n",
        "    learning_rate = 0.001\n",
        "    weight_decay = 0.0001\n",
        "    batch_size = 256\n",
        "    num_epochs = 100\n",
        "    image_size = 32\n",
        "    obj_image_size = 32\n",
        "    patch_size = 4\n",
        "    num_patches = (image_size // patch_size) ** 2\n",
        "    projection_dim = 128  # 임베딩 차원을 CIFAR-10에 맞게 조정\n",
        "    num_heads = 4  # 어텐션 헤드 수를 CIFAR-10에 맞게 조정\n",
        "    transformer_layers = 6  # 트랜스포머 레이어 수를 CIFAR-10에 맞게 조정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il3MRotyerL8",
        "outputId": "925056b2-2d9f-4d03-b17b-be1d2f495fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "196/196 [==============================] - 48s 134ms/step - loss: 2.2243 - accuracy: 0.2054 - val_loss: 1.8063 - val_accuracy: 0.3180\n",
            "Epoch 2/100\n",
            "196/196 [==============================] - 24s 124ms/step - loss: 1.6572 - accuracy: 0.3664 - val_loss: 1.5024 - val_accuracy: 0.4304\n",
            "Epoch 3/100\n",
            "196/196 [==============================] - 24s 124ms/step - loss: 1.4163 - accuracy: 0.4808 - val_loss: 1.3156 - val_accuracy: 0.5226\n",
            "Epoch 4/100\n",
            "196/196 [==============================] - 24s 124ms/step - loss: 1.2745 - accuracy: 0.5378 - val_loss: 1.2384 - val_accuracy: 0.5500\n",
            "Epoch 5/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 1.1635 - accuracy: 0.5846 - val_loss: 1.1494 - val_accuracy: 0.5889\n",
            "Epoch 6/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 1.0972 - accuracy: 0.6095 - val_loss: 1.1325 - val_accuracy: 0.5946\n",
            "Epoch 7/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 1.0343 - accuracy: 0.6335 - val_loss: 1.1078 - val_accuracy: 0.6044\n",
            "Epoch 8/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.9791 - accuracy: 0.6538 - val_loss: 1.0631 - val_accuracy: 0.6237\n",
            "Epoch 9/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.9318 - accuracy: 0.6730 - val_loss: 1.0774 - val_accuracy: 0.6188\n",
            "Epoch 10/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.8859 - accuracy: 0.6884 - val_loss: 1.1068 - val_accuracy: 0.6150\n",
            "Epoch 11/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.8501 - accuracy: 0.7021 - val_loss: 1.0424 - val_accuracy: 0.6390\n",
            "Epoch 12/100\n",
            "196/196 [==============================] - 25s 129ms/step - loss: 0.8213 - accuracy: 0.7128 - val_loss: 1.0411 - val_accuracy: 0.6449\n",
            "Epoch 13/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.7844 - accuracy: 0.7262 - val_loss: 1.0244 - val_accuracy: 0.6499\n",
            "Epoch 14/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.7506 - accuracy: 0.7385 - val_loss: 1.0436 - val_accuracy: 0.6494\n",
            "Epoch 15/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.7235 - accuracy: 0.7474 - val_loss: 1.0616 - val_accuracy: 0.6479\n",
            "Epoch 16/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.6924 - accuracy: 0.7565 - val_loss: 1.0645 - val_accuracy: 0.6399\n",
            "Epoch 17/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.6687 - accuracy: 0.7676 - val_loss: 1.0502 - val_accuracy: 0.6486\n",
            "Epoch 18/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.6446 - accuracy: 0.7768 - val_loss: 1.0267 - val_accuracy: 0.6555\n",
            "Epoch 19/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.6154 - accuracy: 0.7863 - val_loss: 1.1214 - val_accuracy: 0.6397\n",
            "Epoch 20/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.5952 - accuracy: 0.7936 - val_loss: 1.0860 - val_accuracy: 0.6481\n",
            "Epoch 21/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.5849 - accuracy: 0.7972 - val_loss: 1.1187 - val_accuracy: 0.6468\n",
            "Epoch 22/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.5522 - accuracy: 0.8087 - val_loss: 1.1418 - val_accuracy: 0.6448\n",
            "Epoch 23/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.5334 - accuracy: 0.8140 - val_loss: 1.0585 - val_accuracy: 0.6676\n",
            "Epoch 24/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.5249 - accuracy: 0.8179 - val_loss: 1.1911 - val_accuracy: 0.6467\n",
            "Epoch 25/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.5205 - accuracy: 0.8196 - val_loss: 1.1302 - val_accuracy: 0.6481\n",
            "Epoch 26/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.4837 - accuracy: 0.8325 - val_loss: 1.1955 - val_accuracy: 0.6390\n",
            "Epoch 27/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.4802 - accuracy: 0.8346 - val_loss: 1.1712 - val_accuracy: 0.6510\n",
            "Epoch 28/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.4596 - accuracy: 0.8423 - val_loss: 1.2173 - val_accuracy: 0.6498\n",
            "Epoch 29/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.4548 - accuracy: 0.8439 - val_loss: 1.1580 - val_accuracy: 0.6534\n",
            "Epoch 30/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.4275 - accuracy: 0.8512 - val_loss: 1.1808 - val_accuracy: 0.6520\n",
            "Epoch 31/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.4257 - accuracy: 0.8535 - val_loss: 1.2492 - val_accuracy: 0.6432\n",
            "Epoch 32/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.4238 - accuracy: 0.8551 - val_loss: 1.2836 - val_accuracy: 0.6416\n",
            "Epoch 33/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.4044 - accuracy: 0.8599 - val_loss: 1.2128 - val_accuracy: 0.6472\n",
            "Epoch 34/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.3853 - accuracy: 0.8671 - val_loss: 1.2240 - val_accuracy: 0.6538\n",
            "Epoch 35/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.3951 - accuracy: 0.8627 - val_loss: 1.1821 - val_accuracy: 0.6604\n",
            "Epoch 36/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.3747 - accuracy: 0.8710 - val_loss: 1.2656 - val_accuracy: 0.6588\n",
            "Epoch 37/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3550 - accuracy: 0.8771 - val_loss: 1.2025 - val_accuracy: 0.6680\n",
            "Epoch 38/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.3742 - accuracy: 0.8701 - val_loss: 1.2649 - val_accuracy: 0.6470\n",
            "Epoch 39/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3521 - accuracy: 0.8776 - val_loss: 1.2253 - val_accuracy: 0.6571\n",
            "Epoch 40/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.3439 - accuracy: 0.8821 - val_loss: 1.2627 - val_accuracy: 0.6585\n",
            "Epoch 41/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.3412 - accuracy: 0.8814 - val_loss: 1.3400 - val_accuracy: 0.6487\n",
            "Epoch 42/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3371 - accuracy: 0.8830 - val_loss: 1.2723 - val_accuracy: 0.6579\n",
            "Epoch 43/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3254 - accuracy: 0.8879 - val_loss: 1.2759 - val_accuracy: 0.6604\n",
            "Epoch 44/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3279 - accuracy: 0.8867 - val_loss: 1.2654 - val_accuracy: 0.6614\n",
            "Epoch 45/100\n",
            "196/196 [==============================] - 24s 124ms/step - loss: 0.3332 - accuracy: 0.8848 - val_loss: 1.3224 - val_accuracy: 0.6603\n",
            "Epoch 46/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3187 - accuracy: 0.8884 - val_loss: 1.3315 - val_accuracy: 0.6529\n",
            "Epoch 47/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.3144 - accuracy: 0.8902 - val_loss: 1.2937 - val_accuracy: 0.6599\n",
            "Epoch 48/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.3112 - accuracy: 0.8927 - val_loss: 1.3301 - val_accuracy: 0.6519\n",
            "Epoch 49/100\n",
            "196/196 [==============================] - 24s 123ms/step - loss: 0.2965 - accuracy: 0.8972 - val_loss: 1.3217 - val_accuracy: 0.6557\n",
            "Epoch 50/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.2962 - accuracy: 0.8982 - val_loss: 1.2800 - val_accuracy: 0.6536\n",
            "Epoch 51/100\n",
            "196/196 [==============================] - 24s 122ms/step - loss: 0.2940 - accuracy: 0.8992 - val_loss: 1.3411 - val_accuracy: 0.6542\n",
            "Epoch 52/100\n",
            "196/196 [==============================] - 25s 126ms/step - loss: 0.2897 - accuracy: 0.9010 - val_loss: 1.3219 - val_accuracy: 0.6630\n",
            "Epoch 53/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2978 - accuracy: 0.8965 - val_loss: 1.3049 - val_accuracy: 0.6607\n",
            "Epoch 54/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.2821 - accuracy: 0.9031 - val_loss: 1.3830 - val_accuracy: 0.6526\n",
            "Epoch 55/100\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.2856 - accuracy: 0.9013 - val_loss: 1.3561 - val_accuracy: 0.6462\n",
            "Epoch 56/100\n",
            "196/196 [==============================] - 25s 127ms/step - loss: 0.2747 - accuracy: 0.9055 - val_loss: 1.3920 - val_accuracy: 0.6553\n",
            "Epoch 57/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2802 - accuracy: 0.9032 - val_loss: 1.3460 - val_accuracy: 0.6530\n",
            "Epoch 58/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2754 - accuracy: 0.9060 - val_loss: 1.3291 - val_accuracy: 0.6588\n",
            "Epoch 59/100\n",
            "196/196 [==============================] - 23s 120ms/step - loss: 0.2677 - accuracy: 0.9079 - val_loss: 1.4504 - val_accuracy: 0.6530\n",
            "Epoch 60/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2741 - accuracy: 0.9058 - val_loss: 1.3761 - val_accuracy: 0.6563\n",
            "Epoch 61/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2678 - accuracy: 0.9085 - val_loss: 1.3654 - val_accuracy: 0.6615\n",
            "Epoch 62/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2577 - accuracy: 0.9113 - val_loss: 1.4212 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2644 - accuracy: 0.9090 - val_loss: 1.3872 - val_accuracy: 0.6564\n",
            "Epoch 64/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2671 - accuracy: 0.9058 - val_loss: 1.4180 - val_accuracy: 0.6568\n",
            "Epoch 65/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2509 - accuracy: 0.9145 - val_loss: 1.3684 - val_accuracy: 0.6625\n",
            "Epoch 66/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2600 - accuracy: 0.9091 - val_loss: 1.3789 - val_accuracy: 0.6560\n",
            "Epoch 67/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2546 - accuracy: 0.9118 - val_loss: 1.3922 - val_accuracy: 0.6576\n",
            "Epoch 68/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2688 - accuracy: 0.9080 - val_loss: 1.4112 - val_accuracy: 0.6516\n",
            "Epoch 69/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2443 - accuracy: 0.9158 - val_loss: 1.3521 - val_accuracy: 0.6598\n",
            "Epoch 70/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2657 - accuracy: 0.9077 - val_loss: 1.4873 - val_accuracy: 0.6523\n",
            "Epoch 71/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2496 - accuracy: 0.9147 - val_loss: 1.4622 - val_accuracy: 0.6487\n",
            "Epoch 72/100\n",
            "196/196 [==============================] - 25s 126ms/step - loss: 0.2380 - accuracy: 0.9178 - val_loss: 1.3888 - val_accuracy: 0.6610\n",
            "Epoch 73/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2487 - accuracy: 0.9137 - val_loss: 1.4418 - val_accuracy: 0.6616\n",
            "Epoch 74/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2387 - accuracy: 0.9166 - val_loss: 1.3570 - val_accuracy: 0.6623\n",
            "Epoch 75/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2410 - accuracy: 0.9178 - val_loss: 1.4320 - val_accuracy: 0.6599\n",
            "Epoch 76/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2478 - accuracy: 0.9144 - val_loss: 1.3931 - val_accuracy: 0.6676\n",
            "Epoch 77/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2295 - accuracy: 0.9204 - val_loss: 1.4441 - val_accuracy: 0.6543\n",
            "Epoch 78/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2382 - accuracy: 0.9189 - val_loss: 1.3815 - val_accuracy: 0.6572\n",
            "Epoch 79/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2492 - accuracy: 0.9143 - val_loss: 1.4427 - val_accuracy: 0.6610\n",
            "Epoch 80/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2351 - accuracy: 0.9195 - val_loss: 1.4049 - val_accuracy: 0.6632\n",
            "Epoch 81/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2295 - accuracy: 0.9208 - val_loss: 1.4224 - val_accuracy: 0.6576\n",
            "Epoch 82/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2365 - accuracy: 0.9193 - val_loss: 1.3836 - val_accuracy: 0.6673\n",
            "Epoch 83/100\n",
            "196/196 [==============================] - 25s 126ms/step - loss: 0.2291 - accuracy: 0.9214 - val_loss: 1.3786 - val_accuracy: 0.6602\n",
            "Epoch 84/100\n",
            "196/196 [==============================] - 23s 120ms/step - loss: 0.2454 - accuracy: 0.9157 - val_loss: 1.3891 - val_accuracy: 0.6577\n",
            "Epoch 85/100\n",
            "196/196 [==============================] - 23s 120ms/step - loss: 0.2345 - accuracy: 0.9193 - val_loss: 1.3422 - val_accuracy: 0.6636\n",
            "Epoch 86/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2344 - accuracy: 0.9198 - val_loss: 1.4303 - val_accuracy: 0.6516\n",
            "Epoch 87/100\n",
            "196/196 [==============================] - 24s 124ms/step - loss: 0.2372 - accuracy: 0.9182 - val_loss: 1.4182 - val_accuracy: 0.6635\n",
            "Epoch 88/100\n",
            "196/196 [==============================] - 24s 124ms/step - loss: 0.2279 - accuracy: 0.9220 - val_loss: 1.4269 - val_accuracy: 0.6601\n",
            "Epoch 89/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2232 - accuracy: 0.9224 - val_loss: 1.4834 - val_accuracy: 0.6528\n",
            "Epoch 90/100\n",
            "196/196 [==============================] - 23s 120ms/step - loss: 0.2292 - accuracy: 0.9216 - val_loss: 1.4325 - val_accuracy: 0.6579\n",
            "Epoch 91/100\n",
            "196/196 [==============================] - 25s 125ms/step - loss: 0.2309 - accuracy: 0.9209 - val_loss: 1.3882 - val_accuracy: 0.6577\n",
            "Epoch 92/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2154 - accuracy: 0.9262 - val_loss: 1.5188 - val_accuracy: 0.6518\n",
            "Epoch 93/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2289 - accuracy: 0.9203 - val_loss: 1.4174 - val_accuracy: 0.6663\n",
            "Epoch 94/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2247 - accuracy: 0.9223 - val_loss: 1.4532 - val_accuracy: 0.6669\n",
            "Epoch 95/100\n",
            "196/196 [==============================] - 23s 120ms/step - loss: 0.2246 - accuracy: 0.9232 - val_loss: 1.3978 - val_accuracy: 0.6538\n",
            "Epoch 96/100\n",
            "196/196 [==============================] - 24s 120ms/step - loss: 0.2210 - accuracy: 0.9249 - val_loss: 1.4417 - val_accuracy: 0.6518\n",
            "Epoch 97/100\n",
            "196/196 [==============================] - 23s 120ms/step - loss: 0.2294 - accuracy: 0.9206 - val_loss: 1.4784 - val_accuracy: 0.6556\n",
            "Epoch 98/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2297 - accuracy: 0.9212 - val_loss: 1.3812 - val_accuracy: 0.6525\n",
            "Epoch 99/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2174 - accuracy: 0.9256 - val_loss: 1.3691 - val_accuracy: 0.6608\n",
            "Epoch 100/100\n",
            "196/196 [==============================] - 24s 125ms/step - loss: 0.2222 - accuracy: 0.9241 - val_loss: 1.4005 - val_accuracy: 0.6612\n",
            "==============Training Finished===============\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 1.4005 - accuracy: 0.6612\n",
            "Test Accuracy : 0.6611999869346619\n"
          ]
        }
      ],
      "source": [
        "CFG = CFG()\n",
        "optimizer = tfa.optimizers.AdamW(learning_rate=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
        "\n",
        "model_vit = ImageTransformer(\n",
        "    CFG.image_size, CFG.patch_size, CFG.num_classes, CFG.batch_size,\n",
        "    CFG.projection_dim, CFG.transformer_layers, CFG.num_heads, CFG.projection_dim\n",
        ")\n",
        "model_vit.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tensorflow.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "model_vit.fit(x=train_images, y=train_labels, batch_size=CFG.batch_size, epochs=CFG.num_epochs, validation_data=(test_images, test_labels), shuffle=True)\n",
        "print('==============Training Finished===============')\n",
        "\n",
        "accuracy = 0\n",
        "_, accuracy = model_vit.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test Accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# 데이터 증강 추가\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gelu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.gelu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, dimension: int, heads: int = 8):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dimension = dimension\n",
        "        self.depth = dimension // heads\n",
        "\n",
        "        self.wq = nn.Linear(dimension, dimension)\n",
        "        self.wk = nn.Linear(dimension, dimension)\n",
        "        self.wv = nn.Linear(dimension, dimension)\n",
        "        self.dense = nn.Linear(dimension, dimension)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        def split_heads(x):\n",
        "            x = x.view(batch_size, -1, self.heads, self.depth)\n",
        "            return x.permute(0, 2, 1, 3)\n",
        "\n",
        "        q = split_heads(self.wq(x))\n",
        "        k = split_heads(self.wk(x))\n",
        "        v = split_heads(self.wv(x))\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(q, k, v)\n",
        "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
        "        concat_attention = scaled_attention.view(batch_size, -1, self.dimension)\n",
        "        output = self.dense(concat_attention)\n",
        "        return output\n",
        "\n",
        "    def scaled_dot_product_attention(self, q, k, v):\n",
        "        matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
        "        dk = k.shape[-1]\n",
        "        scaled_attention_logits = matmul_qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32))\n",
        "        softmax = nn.Softmax(dim=-1)\n",
        "        attention_weights = softmax(scaled_attention_logits)\n",
        "        output = torch.matmul(attention_weights, v)\n",
        "        return output, attention_weights\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, dimension, depth, heads, mlp_dimension, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                nn.LayerNorm(dimension),\n",
        "                MultiHeadedAttention(dimension, heads),\n",
        "                nn.LayerNorm(dimension),\n",
        "                MLPBlock(dimension, mlp_dimension, dropout)\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for norm1, attn, norm2, mlp in self.layers:\n",
        "            x = attn(norm1(x)) + x\n",
        "            x = mlp(norm2(x)) + x\n",
        "        return x\n",
        "\n",
        "class ImageTransformer(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, num_classes, dimension, depth, heads, mlp_dimension, channels=3):\n",
        "        super(ImageTransformer, self).__init__()\n",
        "        assert image_size % patch_size == 0, 'invalid patch size for image size'\n",
        "\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "        self.dimension = dimension\n",
        "\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dimension))\n",
        "        self.classification_token = nn.Parameter(torch.randn(1, 1, dimension))\n",
        "\n",
        "        self.patch_projection = nn.Linear(patch_size * patch_size * channels, dimension)\n",
        "        self.transformer = TransformerEncoder(dimension, depth, heads, mlp_dimension)\n",
        "        self.norm = nn.LayerNorm(dimension)\n",
        "        self.fc = nn.Linear(dimension, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)  # 드롭아웃 비율 증가\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        patches = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
        "        patches = patches.contiguous().view(batch_size, -1, self.patch_size * self.patch_size * x.shape[1])\n",
        "        x = self.patch_projection(patches)\n",
        "\n",
        "        cls_tokens = self.classification_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.positional_embedding\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x[:, 0])\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 모델 및 하이퍼파라미터 설정\n",
        "model = ImageTransformer(\n",
        "    image_size=32, patch_size=4, num_classes=10, dimension=128, depth=6, heads=4, mlp_dimension=256\n",
        ").to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pp2ngxraBbV",
        "outputId": "00a53329-a98d-4af4-c0ff-28dd21b006e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43735952.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "# 학습\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # 훈련 단계\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(trainloader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    # 검증 단계\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(testloader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    remaining_time = epoch_time * (num_epochs - epoch - 1)\n",
        "    eta = time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, ETA: {eta}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqcaCrNadgqv",
        "outputId": "2a51b719-64e0-453b-88bf-b8b77e993312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.0029, Accuracy: 26.27%, Val Loss: 1.7053, Val Accuracy: 38.70%, ETA: 00:20:20\n",
            "Epoch 2/100, Loss: 1.7255, Accuracy: 37.03%, Val Loss: 1.5671, Val Accuracy: 43.71%, ETA: 00:18:46\n",
            "Epoch 3/100, Loss: 1.6263, Accuracy: 41.04%, Val Loss: 1.5043, Val Accuracy: 44.97%, ETA: 00:18:29\n",
            "Epoch 4/100, Loss: 1.5714, Accuracy: 43.07%, Val Loss: 1.4557, Val Accuracy: 47.44%, ETA: 00:18:19\n",
            "Epoch 5/100, Loss: 1.5279, Accuracy: 44.79%, Val Loss: 1.4151, Val Accuracy: 48.57%, ETA: 00:17:50\n",
            "Epoch 6/100, Loss: 1.4905, Accuracy: 45.96%, Val Loss: 1.3980, Val Accuracy: 49.32%, ETA: 00:17:46\n",
            "Epoch 7/100, Loss: 1.4641, Accuracy: 47.02%, Val Loss: 1.3685, Val Accuracy: 51.24%, ETA: 00:17:24\n",
            "Epoch 8/100, Loss: 1.4362, Accuracy: 48.06%, Val Loss: 1.3417, Val Accuracy: 51.53%, ETA: 00:17:41\n",
            "Epoch 9/100, Loss: 1.4073, Accuracy: 49.29%, Val Loss: 1.3142, Val Accuracy: 52.35%, ETA: 00:17:21\n",
            "Epoch 10/100, Loss: 1.3851, Accuracy: 50.23%, Val Loss: 1.3227, Val Accuracy: 52.90%, ETA: 00:16:46\n",
            "Epoch 11/100, Loss: 1.3607, Accuracy: 51.22%, Val Loss: 1.2854, Val Accuracy: 53.82%, ETA: 00:17:01\n",
            "Epoch 12/100, Loss: 1.3398, Accuracy: 51.97%, Val Loss: 1.2382, Val Accuracy: 55.81%, ETA: 00:16:54\n",
            "Epoch 13/100, Loss: 1.3154, Accuracy: 52.84%, Val Loss: 1.2220, Val Accuracy: 56.06%, ETA: 00:16:34\n",
            "Epoch 14/100, Loss: 1.2922, Accuracy: 53.18%, Val Loss: 1.2225, Val Accuracy: 55.94%, ETA: 00:16:07\n",
            "Epoch 15/100, Loss: 1.2719, Accuracy: 54.39%, Val Loss: 1.1905, Val Accuracy: 57.65%, ETA: 00:16:27\n",
            "Epoch 16/100, Loss: 1.2535, Accuracy: 55.19%, Val Loss: 1.1638, Val Accuracy: 58.33%, ETA: 00:16:10\n",
            "Epoch 17/100, Loss: 1.2370, Accuracy: 55.81%, Val Loss: 1.1613, Val Accuracy: 58.33%, ETA: 00:15:46\n",
            "Epoch 18/100, Loss: 1.2194, Accuracy: 56.52%, Val Loss: 1.1626, Val Accuracy: 58.65%, ETA: 00:15:39\n",
            "Epoch 19/100, Loss: 1.2027, Accuracy: 57.04%, Val Loss: 1.1285, Val Accuracy: 58.88%, ETA: 00:15:16\n",
            "Epoch 20/100, Loss: 1.1868, Accuracy: 57.44%, Val Loss: 1.1144, Val Accuracy: 60.16%, ETA: 00:14:58\n",
            "Epoch 21/100, Loss: 1.1698, Accuracy: 58.21%, Val Loss: 1.1044, Val Accuracy: 61.03%, ETA: 00:15:21\n",
            "Epoch 22/100, Loss: 1.1527, Accuracy: 58.89%, Val Loss: 1.0807, Val Accuracy: 61.71%, ETA: 00:14:54\n",
            "Epoch 23/100, Loss: 1.1415, Accuracy: 59.37%, Val Loss: 1.0834, Val Accuracy: 61.19%, ETA: 00:14:49\n",
            "Epoch 24/100, Loss: 1.1237, Accuracy: 60.15%, Val Loss: 1.0630, Val Accuracy: 62.22%, ETA: 00:14:18\n",
            "Epoch 25/100, Loss: 1.1090, Accuracy: 60.66%, Val Loss: 1.0307, Val Accuracy: 63.48%, ETA: 00:14:17\n",
            "Epoch 26/100, Loss: 1.0896, Accuracy: 61.79%, Val Loss: 1.0440, Val Accuracy: 62.39%, ETA: 00:14:02\n",
            "Epoch 27/100, Loss: 1.0822, Accuracy: 61.80%, Val Loss: 1.0187, Val Accuracy: 63.40%, ETA: 00:13:57\n",
            "Epoch 28/100, Loss: 1.0659, Accuracy: 62.34%, Val Loss: 1.0003, Val Accuracy: 64.26%, ETA: 00:13:39\n",
            "Epoch 29/100, Loss: 1.0511, Accuracy: 62.67%, Val Loss: 0.9908, Val Accuracy: 65.20%, ETA: 00:13:46\n",
            "Epoch 30/100, Loss: 1.0459, Accuracy: 63.10%, Val Loss: 0.9697, Val Accuracy: 65.29%, ETA: 00:13:38\n",
            "Epoch 31/100, Loss: 1.0327, Accuracy: 63.58%, Val Loss: 0.9469, Val Accuracy: 65.87%, ETA: 00:13:14\n",
            "Epoch 32/100, Loss: 1.0173, Accuracy: 64.10%, Val Loss: 0.9405, Val Accuracy: 67.02%, ETA: 00:12:51\n",
            "Epoch 33/100, Loss: 1.0012, Accuracy: 64.68%, Val Loss: 0.9418, Val Accuracy: 66.20%, ETA: 00:12:56\n",
            "Epoch 34/100, Loss: 0.9886, Accuracy: 65.31%, Val Loss: 0.9253, Val Accuracy: 67.07%, ETA: 00:12:18\n",
            "Epoch 35/100, Loss: 0.9809, Accuracy: 65.38%, Val Loss: 0.9052, Val Accuracy: 67.76%, ETA: 00:12:14\n",
            "Epoch 36/100, Loss: 0.9662, Accuracy: 66.09%, Val Loss: 0.9182, Val Accuracy: 66.83%, ETA: 00:12:04\n",
            "Epoch 37/100, Loss: 0.9589, Accuracy: 66.43%, Val Loss: 0.8974, Val Accuracy: 68.29%, ETA: 00:12:11\n",
            "Epoch 38/100, Loss: 0.9491, Accuracy: 66.64%, Val Loss: 0.8919, Val Accuracy: 68.76%, ETA: 00:11:59\n",
            "Epoch 39/100, Loss: 0.9354, Accuracy: 67.14%, Val Loss: 0.8821, Val Accuracy: 68.90%, ETA: 00:11:38\n",
            "Epoch 40/100, Loss: 0.9230, Accuracy: 67.50%, Val Loss: 0.8663, Val Accuracy: 69.32%, ETA: 00:11:17\n",
            "Epoch 41/100, Loss: 0.9138, Accuracy: 67.80%, Val Loss: 0.8663, Val Accuracy: 69.55%, ETA: 00:11:38\n",
            "Epoch 42/100, Loss: 0.8992, Accuracy: 68.25%, Val Loss: 0.8729, Val Accuracy: 69.26%, ETA: 00:11:32\n",
            "Epoch 43/100, Loss: 0.8905, Accuracy: 68.82%, Val Loss: 0.8585, Val Accuracy: 70.42%, ETA: 00:10:53\n",
            "Epoch 44/100, Loss: 0.8850, Accuracy: 69.17%, Val Loss: 0.8338, Val Accuracy: 70.74%, ETA: 00:10:42\n",
            "Epoch 45/100, Loss: 0.8753, Accuracy: 69.39%, Val Loss: 0.8141, Val Accuracy: 71.11%, ETA: 00:10:25\n",
            "Epoch 46/100, Loss: 0.8628, Accuracy: 69.68%, Val Loss: 0.8396, Val Accuracy: 70.13%, ETA: 00:10:08\n",
            "Epoch 47/100, Loss: 0.8574, Accuracy: 69.82%, Val Loss: 0.8402, Val Accuracy: 70.63%, ETA: 00:09:56\n",
            "Epoch 48/100, Loss: 0.8438, Accuracy: 70.45%, Val Loss: 0.8204, Val Accuracy: 71.31%, ETA: 00:09:55\n",
            "Epoch 49/100, Loss: 0.8357, Accuracy: 71.03%, Val Loss: 0.8187, Val Accuracy: 71.61%, ETA: 00:09:38\n",
            "Epoch 50/100, Loss: 0.8267, Accuracy: 70.84%, Val Loss: 0.8224, Val Accuracy: 71.94%, ETA: 00:09:47\n",
            "Epoch 51/100, Loss: 0.8257, Accuracy: 70.97%, Val Loss: 0.8082, Val Accuracy: 72.05%, ETA: 00:09:09\n",
            "Epoch 52/100, Loss: 0.8107, Accuracy: 71.64%, Val Loss: 0.7959, Val Accuracy: 72.37%, ETA: 00:09:17\n",
            "Epoch 53/100, Loss: 0.8068, Accuracy: 71.94%, Val Loss: 0.7872, Val Accuracy: 72.06%, ETA: 00:08:44\n",
            "Epoch 54/100, Loss: 0.7953, Accuracy: 72.46%, Val Loss: 0.7833, Val Accuracy: 72.45%, ETA: 00:08:37\n",
            "Epoch 55/100, Loss: 0.7854, Accuracy: 72.25%, Val Loss: 0.7627, Val Accuracy: 73.40%, ETA: 00:08:36\n",
            "Epoch 56/100, Loss: 0.7836, Accuracy: 72.40%, Val Loss: 0.7545, Val Accuracy: 73.70%, ETA: 00:08:21\n",
            "Epoch 57/100, Loss: 0.7735, Accuracy: 72.89%, Val Loss: 0.7533, Val Accuracy: 74.14%, ETA: 00:08:08\n",
            "Epoch 58/100, Loss: 0.7660, Accuracy: 73.34%, Val Loss: 0.7642, Val Accuracy: 74.12%, ETA: 00:08:27\n",
            "Epoch 59/100, Loss: 0.7606, Accuracy: 73.38%, Val Loss: 0.7363, Val Accuracy: 74.51%, ETA: 00:07:42\n",
            "Epoch 60/100, Loss: 0.7491, Accuracy: 73.86%, Val Loss: 0.7458, Val Accuracy: 73.69%, ETA: 00:07:44\n",
            "Epoch 61/100, Loss: 0.7439, Accuracy: 74.08%, Val Loss: 0.7367, Val Accuracy: 74.55%, ETA: 00:07:25\n",
            "Epoch 62/100, Loss: 0.7340, Accuracy: 74.26%, Val Loss: 0.7335, Val Accuracy: 74.78%, ETA: 00:07:17\n",
            "Epoch 63/100, Loss: 0.7297, Accuracy: 74.46%, Val Loss: 0.7277, Val Accuracy: 75.12%, ETA: 00:07:04\n",
            "Epoch 64/100, Loss: 0.7160, Accuracy: 74.97%, Val Loss: 0.7242, Val Accuracy: 75.08%, ETA: 00:06:52\n",
            "Epoch 65/100, Loss: 0.7191, Accuracy: 74.75%, Val Loss: 0.7211, Val Accuracy: 74.87%, ETA: 00:06:44\n",
            "Epoch 66/100, Loss: 0.7063, Accuracy: 75.53%, Val Loss: 0.7250, Val Accuracy: 74.72%, ETA: 00:06:35\n",
            "Epoch 67/100, Loss: 0.7032, Accuracy: 75.47%, Val Loss: 0.7237, Val Accuracy: 75.56%, ETA: 00:06:17\n",
            "Epoch 68/100, Loss: 0.6953, Accuracy: 75.63%, Val Loss: 0.7292, Val Accuracy: 75.34%, ETA: 00:06:04\n",
            "Epoch 69/100, Loss: 0.6886, Accuracy: 75.96%, Val Loss: 0.7099, Val Accuracy: 75.94%, ETA: 00:05:49\n",
            "Epoch 70/100, Loss: 0.6826, Accuracy: 76.25%, Val Loss: 0.7284, Val Accuracy: 75.04%, ETA: 00:05:48\n",
            "Epoch 71/100, Loss: 0.6873, Accuracy: 75.87%, Val Loss: 0.7066, Val Accuracy: 75.88%, ETA: 00:05:33\n",
            "Epoch 72/100, Loss: 0.6713, Accuracy: 76.42%, Val Loss: 0.7109, Val Accuracy: 76.21%, ETA: 00:05:24\n",
            "Epoch 73/100, Loss: 0.6665, Accuracy: 76.69%, Val Loss: 0.7061, Val Accuracy: 75.41%, ETA: 00:05:04\n",
            "Epoch 74/100, Loss: 0.6612, Accuracy: 76.94%, Val Loss: 0.6938, Val Accuracy: 76.36%, ETA: 00:04:53\n",
            "Epoch 75/100, Loss: 0.6518, Accuracy: 77.31%, Val Loss: 0.7019, Val Accuracy: 75.80%, ETA: 00:04:51\n",
            "Epoch 76/100, Loss: 0.6477, Accuracy: 77.32%, Val Loss: 0.6905, Val Accuracy: 76.44%, ETA: 00:04:34\n",
            "Epoch 77/100, Loss: 0.6380, Accuracy: 77.77%, Val Loss: 0.6922, Val Accuracy: 76.41%, ETA: 00:04:19\n",
            "Epoch 78/100, Loss: 0.6320, Accuracy: 77.91%, Val Loss: 0.6959, Val Accuracy: 76.48%, ETA: 00:04:16\n",
            "Epoch 79/100, Loss: 0.6324, Accuracy: 78.06%, Val Loss: 0.6777, Val Accuracy: 76.56%, ETA: 00:04:06\n",
            "Epoch 80/100, Loss: 0.6316, Accuracy: 77.81%, Val Loss: 0.7109, Val Accuracy: 75.73%, ETA: 00:03:46\n",
            "Epoch 81/100, Loss: 0.6215, Accuracy: 78.39%, Val Loss: 0.6656, Val Accuracy: 77.42%, ETA: 00:03:40\n",
            "Epoch 82/100, Loss: 0.6144, Accuracy: 78.50%, Val Loss: 0.6881, Val Accuracy: 77.18%, ETA: 00:03:31\n",
            "Epoch 83/100, Loss: 0.6097, Accuracy: 78.70%, Val Loss: 0.6734, Val Accuracy: 77.13%, ETA: 00:03:19\n",
            "Epoch 84/100, Loss: 0.5982, Accuracy: 79.10%, Val Loss: 0.6590, Val Accuracy: 77.66%, ETA: 00:03:05\n",
            "Epoch 85/100, Loss: 0.6032, Accuracy: 78.95%, Val Loss: 0.6553, Val Accuracy: 77.86%, ETA: 00:02:53\n",
            "Epoch 86/100, Loss: 0.5929, Accuracy: 79.23%, Val Loss: 0.6701, Val Accuracy: 77.65%, ETA: 00:02:40\n",
            "Epoch 87/100, Loss: 0.5903, Accuracy: 79.24%, Val Loss: 0.6677, Val Accuracy: 77.60%, ETA: 00:02:29\n",
            "Epoch 88/100, Loss: 0.5885, Accuracy: 79.56%, Val Loss: 0.6426, Val Accuracy: 78.30%, ETA: 00:02:16\n",
            "Epoch 89/100, Loss: 0.5830, Accuracy: 79.74%, Val Loss: 0.6523, Val Accuracy: 78.05%, ETA: 00:02:04\n",
            "Epoch 90/100, Loss: 0.5754, Accuracy: 79.89%, Val Loss: 0.6670, Val Accuracy: 77.35%, ETA: 00:01:54\n",
            "Epoch 91/100, Loss: 0.5717, Accuracy: 80.05%, Val Loss: 0.6421, Val Accuracy: 78.25%, ETA: 00:01:41\n",
            "Epoch 92/100, Loss: 0.5638, Accuracy: 80.25%, Val Loss: 0.6424, Val Accuracy: 78.45%, ETA: 00:01:30\n",
            "Epoch 93/100, Loss: 0.5630, Accuracy: 80.47%, Val Loss: 0.6595, Val Accuracy: 77.67%, ETA: 00:01:25\n",
            "Epoch 94/100, Loss: 0.5595, Accuracy: 80.68%, Val Loss: 0.6617, Val Accuracy: 78.06%, ETA: 00:01:08\n",
            "Epoch 95/100, Loss: 0.5512, Accuracy: 80.89%, Val Loss: 0.6635, Val Accuracy: 78.58%, ETA: 00:00:59\n",
            "Epoch 96/100, Loss: 0.5526, Accuracy: 80.78%, Val Loss: 0.6481, Val Accuracy: 78.34%, ETA: 00:00:47\n",
            "Epoch 97/100, Loss: 0.5424, Accuracy: 81.15%, Val Loss: 0.6429, Val Accuracy: 78.19%, ETA: 00:00:35\n",
            "Epoch 98/100, Loss: 0.5473, Accuracy: 80.78%, Val Loss: 0.6451, Val Accuracy: 78.66%, ETA: 00:00:23\n",
            "Epoch 99/100, Loss: 0.5401, Accuracy: 80.98%, Val Loss: 0.6647, Val Accuracy: 78.07%, ETA: 00:00:11\n",
            "Epoch 100/100, Loss: 0.5297, Accuracy: 81.38%, Val Loss: 0.6647, Val Accuracy: 77.79%, ETA: 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Ewnso4aGog",
        "outputId": "6819c0ff-652b-448a-bf87-e0bc194f3955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 77.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'vit_cifar10.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "id": "cQoJ8BKIdRct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44fff14-e466-4a75-b73b-9b1daaddf9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to vit_cifar10.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "id": "NEDF-BVwDRHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb18b6b5-4480-416c-93b2-fd261987d38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   12\n",
            "  On-line CPU(s) list:    0-11\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:           6\n",
            "    Model:                85\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   6\n",
            "    Socket(s):            1\n",
            "    Stepping:             7\n",
            "    BogoMIPS:             4400.44\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl\n",
            "                          flush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc re\n",
            "                          p_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3\n",
            "                           fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand\n",
            "                           hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp \n",
            "                          ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm\n",
            "                           mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw av\n",
            "                          x512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capab\n",
            "                          ilities\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    192 KiB (6 instances)\n",
            "  L1i:                    192 KiB (6 instances)\n",
            "  L2:                     6 MiB (6 instances)\n",
            "  L3:                     38.5 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0-11\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Not affected\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Not affected\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swa\n",
            "                          pgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Vulnerable; BHI:\n",
            "                           Vulnerable (Syscall hardening enabled)\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.datasets as datasets\n",
        "import time\n",
        "\n",
        "# 데이터 증강 및 정규화 설정\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# CIFAR-10 데이터셋 다운로드 및 로더 설정\n",
        "full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# 전체 데이터를 학습, 검증, 테스트 데이터로 분할\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "train_dataset, val_dataset, _ = random_split(full_dataset, [train_size, val_size, len(full_dataset) - train_size - val_size])\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "WH1XjZPxcjsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c70241a-3b2d-44c9-e88d-e593138fa769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13122836.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gelu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.gelu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, dimension: int, heads: int = 8):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dimension = dimension\n",
        "        self.depth = dimension // heads\n",
        "\n",
        "        self.wq = nn.Linear(dimension, dimension)\n",
        "        self.wk = nn.Linear(dimension, dimension)\n",
        "        self.wv = nn.Linear(dimension, dimension)\n",
        "        self.dense = nn.Linear(dimension, dimension)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        def split_heads(x):\n",
        "            x = x.view(batch_size, -1, self.heads, self.depth)\n",
        "            return x.permute(0, 2, 1, 3)\n",
        "\n",
        "        q = split_heads(self.wq(x))\n",
        "        k = split_heads(self.wk(x))\n",
        "        v = split_heads(self.wv(x))\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(q, k, v)\n",
        "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
        "        concat_attention = scaled_attention.view(batch_size, -1, self.dimension)\n",
        "        output = self.dense(concat_attention)\n",
        "        return output\n",
        "\n",
        "    def scaled_dot_product_attention(self, q, k, v):\n",
        "        matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
        "        dk = k.shape[-1]\n",
        "        scaled_attention_logits = matmul_qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32))\n",
        "        attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)\n",
        "        output = torch.matmul(attention_weights, v)\n",
        "        return output, attention_weights\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, dimension, depth, heads, mlp_dimension, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.ModuleList([\n",
        "                nn.LayerNorm(dimension),\n",
        "                MultiHeadedAttention(dimension, heads),\n",
        "                nn.LayerNorm(dimension),\n",
        "                MLPBlock(dimension, mlp_dimension, dropout)\n",
        "            ])\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for norm1, attn, norm2, mlp in self.layers:\n",
        "            x = attn(norm1(x)) + x\n",
        "            x = mlp(norm2(x)) + x\n",
        "        return x\n",
        "\n",
        "class ImageTransformer(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, num_classes, dimension, depth, heads, mlp_dimension, channels=3):\n",
        "        super(ImageTransformer, self).__init__()\n",
        "        assert image_size % patch_size == 0, 'Invalid patch size for image size'\n",
        "\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "        self.dimension = dimension\n",
        "\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dimension))\n",
        "        self.classification_token = nn.Parameter(torch.randn(1, 1, dimension))\n",
        "\n",
        "        self.patch_projection = nn.Linear(patch_size * patch_size * channels, dimension)\n",
        "        self.transformer = TransformerEncoder(dimension, depth, heads, mlp_dimension)\n",
        "        self.norm = nn.LayerNorm(dimension)\n",
        "        self.fc = nn.Linear(dimension, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        patches = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
        "        patches = patches.contiguous().view(batch_size, -1, self.patch_size * self.patch_size * x.shape[1])\n",
        "        x = self.patch_projection(patches)\n",
        "\n",
        "        cls_tokens = self.classification_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.positional_embedding\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x[:, 0])\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 모델 및 하이퍼파라미터 설정\n",
        "model = ImageTransformer(\n",
        "    image_size=32, patch_size=4, num_classes=10, dimension=128, depth=6, heads=4, mlp_dimension=256\n",
        ").to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "BVKon8bWF-1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(trainloader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    # 검증 단계\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(valloader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    remaining_time = epoch_time * (num_epochs - epoch - 1)\n",
        "    eta = time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, ETA: {eta}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMjeH4cEF4Tj",
        "outputId": "cfae18a9-bdc4-4989-f796-2302b5eeb519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.0683, Accuracy: 23.63%, Val Loss: 1.8194, Val Accuracy: 34.12%, ETA: 00:16:49\n",
            "Epoch 2/100, Loss: 1.7775, Accuracy: 35.13%, Val Loss: 1.7016, Val Accuracy: 37.36%, ETA: 00:15:21\n",
            "Epoch 3/100, Loss: 1.6658, Accuracy: 39.20%, Val Loss: 1.6055, Val Accuracy: 40.84%, ETA: 00:15:11\n",
            "Epoch 4/100, Loss: 1.6077, Accuracy: 41.76%, Val Loss: 1.5572, Val Accuracy: 43.16%, ETA: 00:15:24\n",
            "Epoch 5/100, Loss: 1.5612, Accuracy: 43.49%, Val Loss: 1.5265, Val Accuracy: 44.90%, ETA: 00:14:49\n",
            "Epoch 6/100, Loss: 1.5272, Accuracy: 44.73%, Val Loss: 1.4893, Val Accuracy: 45.70%, ETA: 00:14:31\n",
            "Epoch 7/100, Loss: 1.4909, Accuracy: 46.18%, Val Loss: 1.4664, Val Accuracy: 46.96%, ETA: 00:14:28\n",
            "Epoch 8/100, Loss: 1.4750, Accuracy: 46.67%, Val Loss: 1.4453, Val Accuracy: 47.20%, ETA: 00:14:34\n",
            "Epoch 9/100, Loss: 1.4528, Accuracy: 47.77%, Val Loss: 1.4092, Val Accuracy: 48.62%, ETA: 00:14:30\n",
            "Epoch 10/100, Loss: 1.4187, Accuracy: 49.10%, Val Loss: 1.3900, Val Accuracy: 50.38%, ETA: 00:14:04\n",
            "Epoch 11/100, Loss: 1.3991, Accuracy: 49.63%, Val Loss: 1.3615, Val Accuracy: 50.76%, ETA: 00:14:18\n",
            "Epoch 12/100, Loss: 1.3831, Accuracy: 50.27%, Val Loss: 1.3326, Val Accuracy: 51.66%, ETA: 00:14:05\n",
            "Epoch 13/100, Loss: 1.3658, Accuracy: 50.78%, Val Loss: 1.3371, Val Accuracy: 52.42%, ETA: 00:13:47\n",
            "Epoch 14/100, Loss: 1.3383, Accuracy: 51.94%, Val Loss: 1.3093, Val Accuracy: 52.70%, ETA: 00:13:39\n",
            "Epoch 15/100, Loss: 1.3197, Accuracy: 52.58%, Val Loss: 1.3011, Val Accuracy: 52.94%, ETA: 00:13:21\n",
            "Epoch 16/100, Loss: 1.3051, Accuracy: 53.20%, Val Loss: 1.3033, Val Accuracy: 53.60%, ETA: 00:13:12\n",
            "Epoch 17/100, Loss: 1.2907, Accuracy: 53.67%, Val Loss: 1.2655, Val Accuracy: 54.68%, ETA: 00:12:57\n",
            "Epoch 18/100, Loss: 1.2766, Accuracy: 54.44%, Val Loss: 1.2647, Val Accuracy: 54.06%, ETA: 00:12:46\n",
            "Epoch 19/100, Loss: 1.2636, Accuracy: 54.83%, Val Loss: 1.2344, Val Accuracy: 56.02%, ETA: 00:12:44\n",
            "Epoch 20/100, Loss: 1.2430, Accuracy: 55.95%, Val Loss: 1.2025, Val Accuracy: 56.42%, ETA: 00:12:28\n",
            "Epoch 21/100, Loss: 1.2273, Accuracy: 56.55%, Val Loss: 1.1894, Val Accuracy: 57.02%, ETA: 00:12:18\n",
            "Epoch 22/100, Loss: 1.2122, Accuracy: 56.88%, Val Loss: 1.2049, Val Accuracy: 56.78%, ETA: 00:12:07\n",
            "Epoch 23/100, Loss: 1.1942, Accuracy: 57.39%, Val Loss: 1.2044, Val Accuracy: 57.20%, ETA: 00:11:54\n",
            "Epoch 24/100, Loss: 1.1879, Accuracy: 57.49%, Val Loss: 1.1552, Val Accuracy: 58.28%, ETA: 00:11:45\n",
            "Epoch 25/100, Loss: 1.1756, Accuracy: 58.34%, Val Loss: 1.1646, Val Accuracy: 59.04%, ETA: 00:11:48\n",
            "Epoch 26/100, Loss: 1.1684, Accuracy: 58.47%, Val Loss: 1.1539, Val Accuracy: 58.42%, ETA: 00:11:48\n",
            "Epoch 27/100, Loss: 1.1488, Accuracy: 59.32%, Val Loss: 1.1355, Val Accuracy: 59.36%, ETA: 00:11:18\n",
            "Epoch 28/100, Loss: 1.1386, Accuracy: 59.49%, Val Loss: 1.1540, Val Accuracy: 59.58%, ETA: 00:11:24\n",
            "Epoch 29/100, Loss: 1.1163, Accuracy: 60.24%, Val Loss: 1.1164, Val Accuracy: 60.00%, ETA: 00:11:00\n",
            "Epoch 30/100, Loss: 1.1172, Accuracy: 60.37%, Val Loss: 1.1099, Val Accuracy: 60.50%, ETA: 00:11:06\n",
            "Epoch 31/100, Loss: 1.0979, Accuracy: 61.22%, Val Loss: 1.0885, Val Accuracy: 60.58%, ETA: 00:10:41\n",
            "Epoch 32/100, Loss: 1.0940, Accuracy: 61.48%, Val Loss: 1.0997, Val Accuracy: 60.48%, ETA: 00:10:34\n",
            "Epoch 33/100, Loss: 1.0780, Accuracy: 62.27%, Val Loss: 1.0716, Val Accuracy: 61.94%, ETA: 00:10:43\n",
            "Epoch 34/100, Loss: 1.0655, Accuracy: 62.57%, Val Loss: 1.0805, Val Accuracy: 61.44%, ETA: 00:10:16\n",
            "Epoch 35/100, Loss: 1.0505, Accuracy: 62.66%, Val Loss: 1.0579, Val Accuracy: 62.28%, ETA: 00:10:02\n",
            "Epoch 36/100, Loss: 1.0441, Accuracy: 62.99%, Val Loss: 1.0635, Val Accuracy: 62.08%, ETA: 00:10:04\n",
            "Epoch 37/100, Loss: 1.0372, Accuracy: 63.61%, Val Loss: 1.0649, Val Accuracy: 61.82%, ETA: 00:10:09\n",
            "Epoch 38/100, Loss: 1.0273, Accuracy: 63.89%, Val Loss: 1.0301, Val Accuracy: 63.72%, ETA: 00:09:32\n",
            "Epoch 39/100, Loss: 1.0102, Accuracy: 64.34%, Val Loss: 1.0385, Val Accuracy: 63.28%, ETA: 00:09:32\n",
            "Epoch 40/100, Loss: 0.9986, Accuracy: 64.89%, Val Loss: 1.0264, Val Accuracy: 63.42%, ETA: 00:09:21\n",
            "Epoch 41/100, Loss: 0.9995, Accuracy: 64.83%, Val Loss: 0.9967, Val Accuracy: 64.30%, ETA: 00:09:16\n",
            "Epoch 42/100, Loss: 0.9912, Accuracy: 65.14%, Val Loss: 1.0211, Val Accuracy: 63.78%, ETA: 00:09:05\n",
            "Epoch 43/100, Loss: 0.9754, Accuracy: 65.78%, Val Loss: 1.0008, Val Accuracy: 64.52%, ETA: 00:08:51\n",
            "Epoch 44/100, Loss: 0.9632, Accuracy: 66.04%, Val Loss: 0.9871, Val Accuracy: 65.78%, ETA: 00:08:41\n",
            "Epoch 45/100, Loss: 0.9580, Accuracy: 66.56%, Val Loss: 0.9738, Val Accuracy: 65.82%, ETA: 00:08:36\n",
            "Epoch 46/100, Loss: 0.9427, Accuracy: 66.92%, Val Loss: 0.9746, Val Accuracy: 65.64%, ETA: 00:08:24\n",
            "Epoch 47/100, Loss: 0.9326, Accuracy: 67.67%, Val Loss: 0.9920, Val Accuracy: 65.18%, ETA: 00:08:20\n",
            "Epoch 48/100, Loss: 0.9301, Accuracy: 67.49%, Val Loss: 0.9480, Val Accuracy: 66.70%, ETA: 00:08:15\n",
            "Epoch 49/100, Loss: 0.9108, Accuracy: 68.12%, Val Loss: 0.9485, Val Accuracy: 66.28%, ETA: 00:08:01\n",
            "Epoch 50/100, Loss: 0.9080, Accuracy: 68.03%, Val Loss: 0.9544, Val Accuracy: 66.80%, ETA: 00:07:48\n",
            "Epoch 51/100, Loss: 0.8999, Accuracy: 68.52%, Val Loss: 0.9289, Val Accuracy: 67.76%, ETA: 00:07:38\n",
            "Epoch 52/100, Loss: 0.8908, Accuracy: 68.59%, Val Loss: 0.9384, Val Accuracy: 67.44%, ETA: 00:07:25\n",
            "Epoch 53/100, Loss: 0.8889, Accuracy: 68.97%, Val Loss: 0.9301, Val Accuracy: 67.54%, ETA: 00:07:27\n",
            "Epoch 54/100, Loss: 0.8751, Accuracy: 69.56%, Val Loss: 0.9125, Val Accuracy: 67.86%, ETA: 00:07:17\n",
            "Epoch 55/100, Loss: 0.8734, Accuracy: 69.61%, Val Loss: 0.9078, Val Accuracy: 68.46%, ETA: 00:07:03\n",
            "Epoch 56/100, Loss: 0.8658, Accuracy: 69.64%, Val Loss: 0.9089, Val Accuracy: 68.12%, ETA: 00:06:46\n",
            "Epoch 57/100, Loss: 0.8526, Accuracy: 69.98%, Val Loss: 0.8808, Val Accuracy: 68.86%, ETA: 00:06:38\n",
            "Epoch 58/100, Loss: 0.8454, Accuracy: 70.42%, Val Loss: 0.8803, Val Accuracy: 69.80%, ETA: 00:06:35\n",
            "Epoch 59/100, Loss: 0.8340, Accuracy: 70.77%, Val Loss: 0.8903, Val Accuracy: 69.20%, ETA: 00:06:28\n",
            "Epoch 60/100, Loss: 0.8299, Accuracy: 71.11%, Val Loss: 0.8719, Val Accuracy: 69.78%, ETA: 00:06:15\n",
            "Epoch 61/100, Loss: 0.8270, Accuracy: 71.14%, Val Loss: 0.8802, Val Accuracy: 68.36%, ETA: 00:06:11\n",
            "Epoch 62/100, Loss: 0.8173, Accuracy: 71.28%, Val Loss: 0.8547, Val Accuracy: 70.04%, ETA: 00:05:55\n",
            "Epoch 63/100, Loss: 0.8116, Accuracy: 71.64%, Val Loss: 0.8578, Val Accuracy: 69.84%, ETA: 00:05:48\n",
            "Epoch 64/100, Loss: 0.7989, Accuracy: 72.17%, Val Loss: 0.8335, Val Accuracy: 71.14%, ETA: 00:05:43\n",
            "Epoch 65/100, Loss: 0.7920, Accuracy: 72.33%, Val Loss: 0.8580, Val Accuracy: 70.40%, ETA: 00:05:29\n",
            "Epoch 66/100, Loss: 0.7969, Accuracy: 72.16%, Val Loss: 0.8294, Val Accuracy: 70.54%, ETA: 00:05:20\n",
            "Epoch 67/100, Loss: 0.7847, Accuracy: 72.56%, Val Loss: 0.8321, Val Accuracy: 71.30%, ETA: 00:05:09\n",
            "Epoch 68/100, Loss: 0.7725, Accuracy: 73.03%, Val Loss: 0.8254, Val Accuracy: 70.94%, ETA: 00:05:11\n",
            "Epoch 69/100, Loss: 0.7704, Accuracy: 72.99%, Val Loss: 0.8267, Val Accuracy: 71.30%, ETA: 00:04:48\n",
            "Epoch 70/100, Loss: 0.7696, Accuracy: 73.11%, Val Loss: 0.8451, Val Accuracy: 71.06%, ETA: 00:04:46\n",
            "Epoch 71/100, Loss: 0.7592, Accuracy: 73.47%, Val Loss: 0.8054, Val Accuracy: 71.96%, ETA: 00:04:25\n",
            "Epoch 72/100, Loss: 0.7446, Accuracy: 74.11%, Val Loss: 0.8333, Val Accuracy: 71.42%, ETA: 00:04:22\n",
            "Epoch 73/100, Loss: 0.7494, Accuracy: 73.88%, Val Loss: 0.8465, Val Accuracy: 70.68%, ETA: 00:04:14\n",
            "Epoch 74/100, Loss: 0.7354, Accuracy: 74.41%, Val Loss: 0.8303, Val Accuracy: 71.38%, ETA: 00:04:09\n",
            "Epoch 75/100, Loss: 0.7291, Accuracy: 74.79%, Val Loss: 0.8186, Val Accuracy: 72.46%, ETA: 00:03:54\n",
            "Epoch 76/100, Loss: 0.7360, Accuracy: 74.39%, Val Loss: 0.8181, Val Accuracy: 72.04%, ETA: 00:03:44\n",
            "Epoch 77/100, Loss: 0.7212, Accuracy: 75.02%, Val Loss: 0.8192, Val Accuracy: 72.08%, ETA: 00:03:36\n",
            "Epoch 78/100, Loss: 0.7137, Accuracy: 75.12%, Val Loss: 0.8059, Val Accuracy: 72.48%, ETA: 00:03:23\n",
            "Epoch 79/100, Loss: 0.7104, Accuracy: 75.14%, Val Loss: 0.8254, Val Accuracy: 71.52%, ETA: 00:03:20\n",
            "Epoch 80/100, Loss: 0.7076, Accuracy: 75.44%, Val Loss: 0.7966, Val Accuracy: 72.26%, ETA: 00:03:06\n",
            "Epoch 81/100, Loss: 0.6972, Accuracy: 75.73%, Val Loss: 0.7834, Val Accuracy: 72.74%, ETA: 00:02:58\n",
            "Epoch 82/100, Loss: 0.6991, Accuracy: 75.65%, Val Loss: 0.8281, Val Accuracy: 71.70%, ETA: 00:02:48\n",
            "Epoch 83/100, Loss: 0.6887, Accuracy: 75.96%, Val Loss: 0.8152, Val Accuracy: 71.80%, ETA: 00:02:42\n",
            "Epoch 84/100, Loss: 0.6835, Accuracy: 76.11%, Val Loss: 0.7780, Val Accuracy: 73.06%, ETA: 00:02:29\n",
            "Epoch 85/100, Loss: 0.6770, Accuracy: 76.29%, Val Loss: 0.7704, Val Accuracy: 74.04%, ETA: 00:02:19\n",
            "Epoch 86/100, Loss: 0.6725, Accuracy: 76.67%, Val Loss: 0.7600, Val Accuracy: 74.02%, ETA: 00:02:09\n",
            "Epoch 87/100, Loss: 0.6682, Accuracy: 76.83%, Val Loss: 0.7553, Val Accuracy: 74.06%, ETA: 00:02:02\n",
            "Epoch 88/100, Loss: 0.6610, Accuracy: 76.86%, Val Loss: 0.7708, Val Accuracy: 73.88%, ETA: 00:01:53\n",
            "Epoch 89/100, Loss: 0.6567, Accuracy: 77.09%, Val Loss: 0.7547, Val Accuracy: 74.16%, ETA: 00:01:41\n",
            "Epoch 90/100, Loss: 0.6512, Accuracy: 77.33%, Val Loss: 0.7559, Val Accuracy: 73.92%, ETA: 00:01:33\n",
            "Epoch 91/100, Loss: 0.6461, Accuracy: 77.68%, Val Loss: 0.7485, Val Accuracy: 74.58%, ETA: 00:01:24\n",
            "Epoch 92/100, Loss: 0.6451, Accuracy: 77.53%, Val Loss: 0.7433, Val Accuracy: 74.62%, ETA: 00:01:16\n",
            "Epoch 93/100, Loss: 0.6352, Accuracy: 77.93%, Val Loss: 0.7797, Val Accuracy: 73.70%, ETA: 00:01:04\n",
            "Epoch 94/100, Loss: 0.6279, Accuracy: 78.12%, Val Loss: 0.7649, Val Accuracy: 74.50%, ETA: 00:00:56\n",
            "Epoch 95/100, Loss: 0.6317, Accuracy: 77.93%, Val Loss: 0.7536, Val Accuracy: 74.34%, ETA: 00:00:46\n",
            "Epoch 96/100, Loss: 0.6265, Accuracy: 78.15%, Val Loss: 0.7626, Val Accuracy: 74.06%, ETA: 00:00:37\n",
            "Epoch 97/100, Loss: 0.6111, Accuracy: 78.77%, Val Loss: 0.7280, Val Accuracy: 75.06%, ETA: 00:00:28\n",
            "Epoch 98/100, Loss: 0.6152, Accuracy: 78.47%, Val Loss: 0.7412, Val Accuracy: 74.54%, ETA: 00:00:18\n",
            "Epoch 99/100, Loss: 0.6126, Accuracy: 78.65%, Val Loss: 0.7515, Val Accuracy: 74.64%, ETA: 00:00:09\n",
            "Epoch 100/100, Loss: 0.6077, Accuracy: 78.72%, Val Loss: 0.7500, Val Accuracy: 75.44%, ETA: 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 평가\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi41ANPcF2gk",
        "outputId": "ac5b0ab6-e9d5-46aa-d25a-414095f6dc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 76.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'vit_cifar10_val.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUI9kQjnGB8y",
        "outputId": "be60b83f-9502-48f6-b75e-c9cc29c01cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to vit_cifar10_val.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.datasets as datasets\n",
        "import time\n",
        "\n",
        "# 데이터 증강 및 정규화 설정\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# CIFAR-10 데이터셋 다운로드 및 로더 설정\n",
        "full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# 전체 데이터를 학습, 검증, 테스트 데이터로 분할\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "train_dataset, val_dataset, _ = random_split(full_dataset, [train_size, val_size, len(full_dataset) - train_size - val_size])\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV-rmSpIGhYr",
        "outputId": "28f1b347-c603-47c8-deb5-f392f0f5e2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13295198.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gelu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.gelu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, dimension: int, heads: int = 8):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dimension = dimension\n",
        "        self.depth = dimension // heads\n",
        "\n",
        "        self.wq = nn.Linear(dimension, dimension)\n",
        "        self.wk = nn.Linear(dimension, dimension)\n",
        "        self.wv = nn.Linear(dimension, dimension)\n",
        "        self.dense = nn.Linear(dimension, dimension)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        def split_heads(x):\n",
        "            x = x.view(batch_size, -1, self.heads, self.depth)\n",
        "            return x.permute(0, 2, 1, 3)\n",
        "\n",
        "        q = split_heads(self.wq(x))\n",
        "        k = split_heads(self.wk(x))\n",
        "        v = split_heads(self.wv(x))\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(q, k, v)\n",
        "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
        "        concat_attention = scaled_attention.view(batch_size, -1, self.dimension)\n",
        "        output = self.dense(concat_attention)\n",
        "        return output\n",
        "\n",
        "    def scaled_dot_product_attention(self, q, k, v):\n",
        "        matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
        "        dk = k.shape[-1]\n",
        "        scaled_attention_logits = matmul_qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32))\n",
        "        attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)\n",
        "        output = torch.matmul(attention_weights, v)\n",
        "        return output, attention_weights\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, dimension, depth, heads, mlp_dimension, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.ModuleList([\n",
        "                nn.LayerNorm(dimension),\n",
        "                MultiHeadedAttention(dimension, heads),\n",
        "                nn.LayerNorm(dimension),\n",
        "                MLPBlock(dimension, mlp_dimension, dropout)\n",
        "            ])\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for norm1, attn, norm2, mlp in self.layers:\n",
        "            x = attn(norm1(x)) + x\n",
        "            x = mlp(norm2(x)) + x\n",
        "        return x\n",
        "\n",
        "class ImageTransformer(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, num_classes, dimension, depth, heads, mlp_dimension, channels=3):\n",
        "        super(ImageTransformer, self).__init__()\n",
        "        assert image_size % patch_size == 0, 'Invalid patch size for image size'\n",
        "\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "        self.dimension = dimension\n",
        "\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dimension))\n",
        "        self.classification_token = nn.Parameter(torch.randn(1, 1, dimension))\n",
        "\n",
        "        self.patch_projection = nn.Linear(patch_size * patch_size * channels, dimension)\n",
        "        self.transformer = TransformerEncoder(dimension, depth, heads, mlp_dimension)\n",
        "        self.norm = nn.LayerNorm(dimension)\n",
        "        self.fc = nn.Linear(dimension, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        patches = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
        "        patches = patches.contiguous().view(batch_size, -1, self.patch_size * self.patch_size * x.shape[1])\n",
        "        x = self.patch_projection(patches)\n",
        "\n",
        "        cls_tokens = self.classification_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.positional_embedding\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x[:, 0])\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 모델 및 하이퍼파라미터 설정\n",
        "model = ImageTransformer(\n",
        "    image_size=32, patch_size=8, num_classes=10, dimension=128, depth=6, heads=4, mlp_dimension=256\n",
        ").to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "mC1O0CsweWoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(trainloader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    # 검증 단계\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(valloader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    remaining_time = epoch_time * (num_epochs - epoch - 1)\n",
        "    eta = time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, ETA: {eta}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsD9iZDTeXp7",
        "outputId": "14f865d8-07a8-4953-d15d-38536d0301aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.0547, Accuracy: 24.16%, Val Loss: 1.8163, Val Accuracy: 32.96%, ETA: 00:16:53\n",
            "Epoch 2/100, Loss: 1.7607, Accuracy: 35.88%, Val Loss: 1.6505, Val Accuracy: 39.08%, ETA: 00:15:25\n",
            "Epoch 3/100, Loss: 1.6689, Accuracy: 39.32%, Val Loss: 1.6196, Val Accuracy: 39.20%, ETA: 00:15:37\n",
            "Epoch 4/100, Loss: 1.6131, Accuracy: 41.33%, Val Loss: 1.5540, Val Accuracy: 42.60%, ETA: 00:15:59\n",
            "Epoch 5/100, Loss: 1.5714, Accuracy: 43.36%, Val Loss: 1.5519, Val Accuracy: 43.88%, ETA: 00:15:39\n",
            "Epoch 6/100, Loss: 1.5432, Accuracy: 44.34%, Val Loss: 1.5129, Val Accuracy: 44.20%, ETA: 00:15:11\n",
            "Epoch 7/100, Loss: 1.5196, Accuracy: 45.21%, Val Loss: 1.4553, Val Accuracy: 46.06%, ETA: 00:15:02\n",
            "Epoch 8/100, Loss: 1.4926, Accuracy: 46.06%, Val Loss: 1.4706, Val Accuracy: 45.84%, ETA: 00:14:52\n",
            "Epoch 9/100, Loss: 1.4795, Accuracy: 46.58%, Val Loss: 1.4511, Val Accuracy: 46.76%, ETA: 00:14:04\n",
            "Epoch 10/100, Loss: 1.4616, Accuracy: 47.54%, Val Loss: 1.4288, Val Accuracy: 48.20%, ETA: 00:14:21\n",
            "Epoch 11/100, Loss: 1.4430, Accuracy: 48.37%, Val Loss: 1.4090, Val Accuracy: 48.84%, ETA: 00:14:04\n",
            "Epoch 12/100, Loss: 1.4327, Accuracy: 48.51%, Val Loss: 1.4149, Val Accuracy: 47.88%, ETA: 00:13:36\n",
            "Epoch 13/100, Loss: 1.4151, Accuracy: 49.10%, Val Loss: 1.3938, Val Accuracy: 49.56%, ETA: 00:13:50\n",
            "Epoch 14/100, Loss: 1.4083, Accuracy: 49.35%, Val Loss: 1.3803, Val Accuracy: 48.62%, ETA: 00:13:21\n",
            "Epoch 15/100, Loss: 1.3887, Accuracy: 50.53%, Val Loss: 1.3618, Val Accuracy: 49.94%, ETA: 00:13:23\n",
            "Epoch 16/100, Loss: 1.3745, Accuracy: 50.71%, Val Loss: 1.3550, Val Accuracy: 50.44%, ETA: 00:13:18\n",
            "Epoch 17/100, Loss: 1.3654, Accuracy: 51.08%, Val Loss: 1.3604, Val Accuracy: 50.54%, ETA: 00:12:50\n",
            "Epoch 18/100, Loss: 1.3512, Accuracy: 51.65%, Val Loss: 1.3291, Val Accuracy: 51.92%, ETA: 00:12:43\n",
            "Epoch 19/100, Loss: 1.3363, Accuracy: 52.37%, Val Loss: 1.3281, Val Accuracy: 52.62%, ETA: 00:12:33\n",
            "Epoch 20/100, Loss: 1.3275, Accuracy: 52.66%, Val Loss: 1.3268, Val Accuracy: 51.56%, ETA: 00:12:52\n",
            "Epoch 21/100, Loss: 1.3196, Accuracy: 52.78%, Val Loss: 1.3030, Val Accuracy: 52.12%, ETA: 00:12:42\n",
            "Epoch 22/100, Loss: 1.3102, Accuracy: 53.19%, Val Loss: 1.2748, Val Accuracy: 53.74%, ETA: 00:12:59\n",
            "Epoch 23/100, Loss: 1.2994, Accuracy: 53.78%, Val Loss: 1.2939, Val Accuracy: 52.96%, ETA: 00:12:19\n",
            "Epoch 24/100, Loss: 1.2908, Accuracy: 53.92%, Val Loss: 1.2849, Val Accuracy: 53.40%, ETA: 00:11:52\n",
            "Epoch 25/100, Loss: 1.2829, Accuracy: 54.09%, Val Loss: 1.2667, Val Accuracy: 53.72%, ETA: 00:12:27\n",
            "Epoch 26/100, Loss: 1.2767, Accuracy: 54.75%, Val Loss: 1.2735, Val Accuracy: 53.14%, ETA: 00:11:33\n",
            "Epoch 27/100, Loss: 1.2633, Accuracy: 54.90%, Val Loss: 1.2616, Val Accuracy: 53.82%, ETA: 00:11:36\n",
            "Epoch 28/100, Loss: 1.2464, Accuracy: 55.37%, Val Loss: 1.2443, Val Accuracy: 54.84%, ETA: 00:11:46\n",
            "Epoch 29/100, Loss: 1.2466, Accuracy: 55.46%, Val Loss: 1.2266, Val Accuracy: 56.30%, ETA: 00:11:36\n",
            "Epoch 30/100, Loss: 1.2356, Accuracy: 55.99%, Val Loss: 1.2322, Val Accuracy: 54.58%, ETA: 00:10:51\n",
            "Epoch 31/100, Loss: 1.2297, Accuracy: 56.26%, Val Loss: 1.2120, Val Accuracy: 56.48%, ETA: 00:10:43\n",
            "Epoch 32/100, Loss: 1.2226, Accuracy: 56.37%, Val Loss: 1.2236, Val Accuracy: 55.72%, ETA: 00:10:43\n",
            "Epoch 33/100, Loss: 1.2088, Accuracy: 56.86%, Val Loss: 1.2264, Val Accuracy: 55.52%, ETA: 00:10:06\n",
            "Epoch 34/100, Loss: 1.2047, Accuracy: 57.35%, Val Loss: 1.1989, Val Accuracy: 56.74%, ETA: 00:10:39\n",
            "Epoch 35/100, Loss: 1.1915, Accuracy: 57.91%, Val Loss: 1.2014, Val Accuracy: 57.50%, ETA: 00:09:59\n",
            "Epoch 36/100, Loss: 1.1926, Accuracy: 57.59%, Val Loss: 1.1794, Val Accuracy: 56.96%, ETA: 00:09:52\n",
            "Epoch 37/100, Loss: 1.1846, Accuracy: 58.06%, Val Loss: 1.1857, Val Accuracy: 57.08%, ETA: 00:10:11\n",
            "Epoch 38/100, Loss: 1.1832, Accuracy: 58.22%, Val Loss: 1.1765, Val Accuracy: 57.56%, ETA: 00:09:45\n",
            "Epoch 39/100, Loss: 1.1689, Accuracy: 58.77%, Val Loss: 1.1938, Val Accuracy: 57.72%, ETA: 00:10:10\n",
            "Epoch 40/100, Loss: 1.1594, Accuracy: 59.16%, Val Loss: 1.1887, Val Accuracy: 57.28%, ETA: 00:09:34\n",
            "Epoch 41/100, Loss: 1.1585, Accuracy: 58.84%, Val Loss: 1.1659, Val Accuracy: 58.26%, ETA: 00:09:06\n",
            "Epoch 42/100, Loss: 1.1473, Accuracy: 59.65%, Val Loss: 1.1587, Val Accuracy: 58.54%, ETA: 00:09:03\n",
            "Epoch 43/100, Loss: 1.1405, Accuracy: 59.69%, Val Loss: 1.1208, Val Accuracy: 60.46%, ETA: 00:08:59\n",
            "Epoch 44/100, Loss: 1.1323, Accuracy: 59.85%, Val Loss: 1.1398, Val Accuracy: 59.76%, ETA: 00:08:40\n",
            "Epoch 45/100, Loss: 1.1227, Accuracy: 60.24%, Val Loss: 1.1349, Val Accuracy: 59.54%, ETA: 00:08:39\n",
            "Epoch 46/100, Loss: 1.1229, Accuracy: 60.06%, Val Loss: 1.1453, Val Accuracy: 59.50%, ETA: 00:08:33\n",
            "Epoch 47/100, Loss: 1.1118, Accuracy: 60.73%, Val Loss: 1.1430, Val Accuracy: 58.68%, ETA: 00:08:22\n",
            "Epoch 48/100, Loss: 1.1145, Accuracy: 60.53%, Val Loss: 1.1347, Val Accuracy: 59.40%, ETA: 00:08:29\n",
            "Epoch 49/100, Loss: 1.1023, Accuracy: 61.01%, Val Loss: 1.1245, Val Accuracy: 60.52%, ETA: 00:07:55\n",
            "Epoch 50/100, Loss: 1.0956, Accuracy: 61.34%, Val Loss: 1.1016, Val Accuracy: 60.92%, ETA: 00:08:01\n",
            "Epoch 51/100, Loss: 1.0950, Accuracy: 61.48%, Val Loss: 1.1301, Val Accuracy: 59.00%, ETA: 00:07:57\n",
            "Epoch 52/100, Loss: 1.0877, Accuracy: 61.72%, Val Loss: 1.1021, Val Accuracy: 59.94%, ETA: 00:07:20\n",
            "Epoch 53/100, Loss: 1.0812, Accuracy: 61.91%, Val Loss: 1.1056, Val Accuracy: 60.36%, ETA: 00:07:13\n",
            "Epoch 54/100, Loss: 1.0721, Accuracy: 62.21%, Val Loss: 1.0939, Val Accuracy: 61.20%, ETA: 00:07:25\n",
            "Epoch 55/100, Loss: 1.0724, Accuracy: 62.06%, Val Loss: 1.1001, Val Accuracy: 60.50%, ETA: 00:07:06\n",
            "Epoch 56/100, Loss: 1.0627, Accuracy: 62.51%, Val Loss: 1.0969, Val Accuracy: 60.92%, ETA: 00:07:01\n",
            "Epoch 57/100, Loss: 1.0579, Accuracy: 62.79%, Val Loss: 1.0935, Val Accuracy: 61.48%, ETA: 00:06:50\n",
            "Epoch 58/100, Loss: 1.0534, Accuracy: 62.60%, Val Loss: 1.1003, Val Accuracy: 61.18%, ETA: 00:06:45\n",
            "Epoch 59/100, Loss: 1.0489, Accuracy: 62.79%, Val Loss: 1.0908, Val Accuracy: 61.34%, ETA: 00:06:31\n",
            "Epoch 60/100, Loss: 1.0454, Accuracy: 63.34%, Val Loss: 1.0594, Val Accuracy: 62.56%, ETA: 00:06:17\n",
            "Epoch 61/100, Loss: 1.0322, Accuracy: 63.55%, Val Loss: 1.0727, Val Accuracy: 62.16%, ETA: 00:06:15\n",
            "Epoch 62/100, Loss: 1.0362, Accuracy: 63.48%, Val Loss: 1.0616, Val Accuracy: 61.14%, ETA: 00:06:06\n",
            "Epoch 63/100, Loss: 1.0340, Accuracy: 63.46%, Val Loss: 1.0586, Val Accuracy: 62.28%, ETA: 00:05:49\n",
            "Epoch 64/100, Loss: 1.0199, Accuracy: 64.04%, Val Loss: 1.0653, Val Accuracy: 60.90%, ETA: 00:05:42\n",
            "Epoch 65/100, Loss: 1.0209, Accuracy: 63.99%, Val Loss: 1.0543, Val Accuracy: 61.78%, ETA: 00:05:34\n",
            "Epoch 66/100, Loss: 1.0155, Accuracy: 64.16%, Val Loss: 1.0520, Val Accuracy: 62.92%, ETA: 00:05:21\n",
            "Epoch 67/100, Loss: 1.0060, Accuracy: 64.43%, Val Loss: 1.0431, Val Accuracy: 63.36%, ETA: 00:05:03\n",
            "Epoch 68/100, Loss: 1.0017, Accuracy: 65.10%, Val Loss: 1.0352, Val Accuracy: 63.72%, ETA: 00:05:00\n",
            "Epoch 69/100, Loss: 0.9975, Accuracy: 65.03%, Val Loss: 1.0221, Val Accuracy: 63.24%, ETA: 00:05:09\n",
            "Epoch 70/100, Loss: 0.9929, Accuracy: 65.27%, Val Loss: 1.0411, Val Accuracy: 62.96%, ETA: 00:04:45\n",
            "Epoch 71/100, Loss: 0.9854, Accuracy: 65.57%, Val Loss: 1.0228, Val Accuracy: 63.52%, ETA: 00:04:38\n",
            "Epoch 72/100, Loss: 0.9871, Accuracy: 65.34%, Val Loss: 1.0079, Val Accuracy: 64.04%, ETA: 00:04:16\n",
            "Epoch 73/100, Loss: 0.9754, Accuracy: 65.63%, Val Loss: 1.0102, Val Accuracy: 63.98%, ETA: 00:04:11\n",
            "Epoch 74/100, Loss: 0.9724, Accuracy: 65.81%, Val Loss: 1.0311, Val Accuracy: 62.92%, ETA: 00:04:09\n",
            "Epoch 75/100, Loss: 0.9706, Accuracy: 66.12%, Val Loss: 1.0195, Val Accuracy: 63.86%, ETA: 00:03:52\n",
            "Epoch 76/100, Loss: 0.9717, Accuracy: 65.90%, Val Loss: 1.0177, Val Accuracy: 64.44%, ETA: 00:03:54\n",
            "Epoch 77/100, Loss: 0.9619, Accuracy: 66.21%, Val Loss: 0.9925, Val Accuracy: 64.30%, ETA: 00:03:42\n",
            "Epoch 78/100, Loss: 0.9575, Accuracy: 66.61%, Val Loss: 1.0046, Val Accuracy: 64.34%, ETA: 00:03:25\n",
            "Epoch 79/100, Loss: 0.9558, Accuracy: 66.50%, Val Loss: 1.0179, Val Accuracy: 64.40%, ETA: 00:03:21\n",
            "Epoch 80/100, Loss: 0.9456, Accuracy: 66.83%, Val Loss: 0.9937, Val Accuracy: 65.12%, ETA: 00:03:11\n",
            "Epoch 81/100, Loss: 0.9494, Accuracy: 66.69%, Val Loss: 0.9904, Val Accuracy: 64.04%, ETA: 00:02:59\n",
            "Epoch 82/100, Loss: 0.9402, Accuracy: 66.88%, Val Loss: 0.9956, Val Accuracy: 64.62%, ETA: 00:02:52\n",
            "Epoch 83/100, Loss: 0.9407, Accuracy: 66.88%, Val Loss: 0.9911, Val Accuracy: 64.52%, ETA: 00:02:37\n",
            "Epoch 84/100, Loss: 0.9274, Accuracy: 67.41%, Val Loss: 0.9963, Val Accuracy: 64.90%, ETA: 00:02:32\n",
            "Epoch 85/100, Loss: 0.9230, Accuracy: 67.63%, Val Loss: 0.9794, Val Accuracy: 64.30%, ETA: 00:02:23\n",
            "Epoch 86/100, Loss: 0.9241, Accuracy: 67.66%, Val Loss: 0.9824, Val Accuracy: 64.98%, ETA: 00:02:15\n",
            "Epoch 87/100, Loss: 0.9171, Accuracy: 67.86%, Val Loss: 0.9901, Val Accuracy: 64.72%, ETA: 00:02:03\n",
            "Epoch 88/100, Loss: 0.9116, Accuracy: 68.15%, Val Loss: 0.9697, Val Accuracy: 65.38%, ETA: 00:01:55\n",
            "Epoch 89/100, Loss: 0.9135, Accuracy: 67.96%, Val Loss: 0.9904, Val Accuracy: 65.24%, ETA: 00:01:44\n",
            "Epoch 90/100, Loss: 0.9128, Accuracy: 68.05%, Val Loss: 0.9692, Val Accuracy: 65.30%, ETA: 00:01:35\n",
            "Epoch 91/100, Loss: 0.9046, Accuracy: 68.31%, Val Loss: 0.9673, Val Accuracy: 64.82%, ETA: 00:01:26\n",
            "Epoch 92/100, Loss: 0.8927, Accuracy: 68.53%, Val Loss: 0.9646, Val Accuracy: 66.22%, ETA: 00:01:16\n",
            "Epoch 93/100, Loss: 0.9016, Accuracy: 68.40%, Val Loss: 0.9709, Val Accuracy: 65.40%, ETA: 00:01:05\n",
            "Epoch 94/100, Loss: 0.8941, Accuracy: 68.73%, Val Loss: 0.9606, Val Accuracy: 66.06%, ETA: 00:00:57\n",
            "Epoch 95/100, Loss: 0.8936, Accuracy: 68.64%, Val Loss: 0.9594, Val Accuracy: 67.08%, ETA: 00:00:47\n",
            "Epoch 96/100, Loss: 0.8822, Accuracy: 69.08%, Val Loss: 0.9465, Val Accuracy: 66.26%, ETA: 00:00:37\n",
            "Epoch 97/100, Loss: 0.8796, Accuracy: 69.15%, Val Loss: 0.9620, Val Accuracy: 66.42%, ETA: 00:00:28\n",
            "Epoch 98/100, Loss: 0.8769, Accuracy: 69.40%, Val Loss: 0.9346, Val Accuracy: 67.14%, ETA: 00:00:19\n",
            "Epoch 99/100, Loss: 0.8729, Accuracy: 69.61%, Val Loss: 0.9467, Val Accuracy: 67.16%, ETA: 00:00:09\n",
            "Epoch 100/100, Loss: 0.8685, Accuracy: 69.59%, Val Loss: 0.9572, Val Accuracy: 66.36%, ETA: 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 평가\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l7K0hxzehDz",
        "outputId": "39c602c8-fd52-438d-d933-4cef098ccf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 68.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'vit_cifar10_val_patch8.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALv9UENGel68",
        "outputId": "1db8d6ce-75a4-4d11-cd56-50512f3647c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to vit_cifar10_val_patch8.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선 시각화\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "cxpIzR8aeqbr",
        "outputId": "0744d024-7d41-408a-a6e3-201f27f0275b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a14acc83661d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 곡선 시각화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxhKtEyJhBcT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}